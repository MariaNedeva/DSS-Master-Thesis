{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "data = pd.read_csv(r'Thesis data\\data_app_cat-241.csv', dtype='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create month column\n",
    "data['month'] = pd.to_datetime(data['startTime']).dt.month"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group the data by studentID, session, month\n",
    "\n",
    "sessions = data.groupby(['StudentID'])['session', 'month'].nunique().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove participants with less than 200 sessions and less than 3 months participation in the study\n",
    "\n",
    "cleaned = sessions[(sessions['session'] > 200)]\n",
    "\n",
    "cleaned = cleaned[(cleaned['month']>=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter only the students who participated more than 3 months and have more than 200 sessions\n",
    "\n",
    "new_data = data[data['StudentID'].isin(cleaned['StudentID'])]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_session =new_data.groupby(['StudentID'])['session'].nunique().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a density plot to see the sessions distribution\n",
    "\n",
    "\n",
    "sns.kdeplot(cleaned['session'], shade=True)\n",
    "\n",
    "#add labels and title\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Density Plot')\n",
    "\n",
    "plt.xlim(0, max(cleaned['session']))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a barplot to see the most active months of phone usage\n",
    "\n",
    "sns.histplot(cleaned['month'])\n",
    "\n",
    "#add labels and title\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Density Plot')\n",
    "\n",
    "plt.xlim(min(cleaned['month']), max(cleaned['month']))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot of the monimum, maximum and average session \n",
    "\n",
    "min_session = student_session['session'].min()\n",
    "max_session = student_session['session'].max()\n",
    "average_session = student_session['session'].mean()\n",
    "\n",
    "#create a DataFrame for the statistics\n",
    "statistics_df = pd.DataFrame({'Statistics': ['Minimum', 'Maximum', 'Average'],\n",
    "                              'Session': [min_session, max_session, average_session]})\n",
    "\n",
    "#display the table\n",
    "statistics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_month =new_data.groupby(['StudentID'])['month', 'session'].nunique().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentage of students who participated for 3-4 months and students who participated for 5-6 months\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#calculate the number of people who participated for 3 and 4 months\n",
    "three_four_months_count = len(student_month[(student_month['month'] <= 3) & (student_month['month'] <= 4)])\n",
    "\n",
    "#calculate the number of people who participated for 5 and 6 months\n",
    "five_six_months_count = len(student_month[(student_month['month'] >= 5) & (student_month['month'] <= 6)])\n",
    "\n",
    "#calculate the total number of participants\n",
    "total_participants = len(student_month)\n",
    "\n",
    "#calculate the percentage of people who participated for 3 and 4 months\n",
    "three_four_months_percentage = (three_four_months_count / total_participants) * 100\n",
    "\n",
    "#calculate the percentage of people who participated for 5 and 6 months\n",
    "five_six_months_percentage = (five_six_months_count / total_participants) * 100\n",
    "\n",
    "#create a bar chart to visualize the percentages\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(['3-4 Months', '5-6 Months'], [three_four_months_percentage, five_six_months_percentage], color=['blue', 'green'])\n",
    "\n",
    "#add labels and title\n",
    "plt.xlabel('Participation Duration')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('Percentage of Participants by Duration')\n",
    "\n",
    "# show the percentages above the bars\n",
    "for i, v in enumerate([three_four_months_percentage, five_six_months_percentage]):\n",
    "    plt.text(i, v + 1, f'{v:.2f}%', ha='center', color='black', fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the most used applications\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the sum of minutes for each category\n",
    "category_minutes = new_data.groupby('better_category')['minutes'].sum()\n",
    "\n",
    "# Get the top 10 categories with the highest minutes\n",
    "top_10_categories = category_minutes.nlargest(10)\n",
    "\n",
    "# Plot the bar chart for the top 10 categories\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=top_10_categories.index, y=top_10_categories.values, palette='viridis')\n",
    "\n",
    "# Add a title and labels\n",
    "plt.title('Top 10 Categories with Highest Amount of Minutes')\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Total Minutes among students')\n",
    "\n",
    "# Rotate x-axis tick labels for better readability\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ratio of phone usage during 6 hour daily windows (6am-12pm, 12pm-6pm, 6pm-12am, 12pm-6am)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create daily windows; measure phone usage in the windows\n",
    "# ratio of phone usage in window\n",
    "\n",
    "new_data['dailyWindow'] = pd.cut(pd.to_datetime(new_data['startTime']).dt.hour,\n",
    "                             bins=[0, 6, 12, 18, 24],\n",
    "                             labels=['0-6', '6-12', '12-18', '18-24'],\n",
    "                             include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group the data on students, month and window\n",
    "#aggregate a list with the minutes to prevent imputiong 0 for the months students' didn't participate\n",
    "usage_per_window = new_data.groupby(['StudentID', 'month', 'dailyWindow'])['minute'].agg(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum the minutes in the lists\n",
    "usage_per_window['minute'] = usage_per_window['minute'].apply(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename minutes column\n",
    "usage_per_window.rename(columns = {'minute': 'total_time_per_window'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the ratio per window\n",
    "\n",
    "usage_per_window_ratio = new_data.groupby(['StudentID', 'month', 'dailyWindow'])['minute'].agg(list).reset_index()\n",
    "\n",
    "usage_per_window_ratio['minute'] = usage_per_window_ratio['minute'].apply(np.sum)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the total phone usage duration per student\n",
    "total_usage_per_student_month = new_data.groupby(['StudentID', 'month'])['minute'].agg(list).reset_index(name='total')\n",
    "\n",
    "total_usage_per_student_month['total'] = total_usage_per_student_month['total'].apply(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge usage_per_window_ratio table and total_usage_per_student_month\n",
    "usage_per_window_ratio.set_index('StudentID', inplace=True)\n",
    "usage_per_window_ratio['StudentID'] = usage_per_window_ratio['StudentID'].astype(int)\n",
    "merged_df_ratio = pd.merge(usage_per_window_ratio, total_usage_per_student_month, on=['StudentID', 'month'])\n",
    "\n",
    "#create ratio column\n",
    "merged_df_ratio['ratio'] = merged_df_ratio['minute'] / merged_df_ratio['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename to ratio_total_phone_usage\n",
    "\n",
    "merged_df_ratio.rename(columns={'ratio': 'ratio_total_usage'}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Ratio of app usage during 6 hour daily windows (6am-12pm, 12pm-6pm, 6pm-12am, 12pm-6am)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1. Ratio Social Networking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by ID, month, and time window\n",
    "grouped = data.groupby(['StudentID', pd.Grouper(key='startTime', freq='6H'), pd.Grouper(key='endTime', freq='M'), 'timeWindow'])\n",
    "\n",
    "# Calculate the total time spent on gaming per ID, month, and time window\n",
    "result = grouped.apply(lambda x: x.loc[x['better_category'] == 'Social_Networking', 'timeMinutes'].sum())\n",
    "\n",
    "result = result.reset_index(name='total_time_SN')\n",
    "\n",
    "# Rename the columns to match the desired output\n",
    "result.columns = ['StudentID', 'startTime', 'endTime', 'timeWindow', 'total_time_SN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['endTime'] = pd.to_datetime(result['endTime'])\n",
    "\n",
    "#group by student id and aggregate time monthly and aggregate a list with total minutes on media per time window\n",
    "\n",
    "group = result.groupby(['StudentID', pd.Grouper(key='endTime', freq='M'), 'timeWindow'])['total_time_SN'].agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a df\n",
    "df = pd.DataFrame(group)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum the total minutes on social media for the whole month\n",
    "group2 = result.groupby(['StudentID', 'endTime'])['total_time_SN'].agg(sum)\n",
    "\n",
    "#merge the time windows with the total time on media\n",
    "merged_df = pd.merge(df, group2, on=['StudentID', 'endTime'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the ratio on social networking per time window\n",
    "merged_df['ratio_SN'] = merged_df['total_time_SN_time_window'] / merged_df['total_time_SN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['ratio_SN'] = merged_df['ratio_SN']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ratio Instant Messaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by ID, month, and time window\n",
    "grouped = data.groupby(['StudentID', pd.Grouper(key='startTime', freq='6H'), pd.Grouper(key='endTime', freq='M'), 'timeWindow'])\n",
    "\n",
    "# Calculate the total time spent on gaming per ID, month, and time window\n",
    "result = grouped.apply(lambda x: x.loc[x['better_category'] == 'Instant_Messaging', 'timeMinutes'].sum())\n",
    "\n",
    "result = result.reset_index(name='total_time_IM')\n",
    "\n",
    "# Rename the columns to match the desired output\n",
    "result.columns = ['StudentID', 'startTime', 'endTime', 'timeWindow', 'total_time_IM']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['endTime'] = pd.to_datetime(result['endTime'])\n",
    "\n",
    "#group by student id and aggregate time monthly and aggregate a list with total minutes on media per time window\n",
    "group_im = result.groupby(['StudentID', pd.Grouper(key='endTime', freq='M'), 'timeWindow'])['total_time_IM'].agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum the total minutes on  media for the whole month\n",
    "group2_im = result.groupby(['StudentID', 'endTime'])['total_time_IM'].agg(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the time windows with the total time on media\n",
    "merged_df_im = pd.merge(group_im, group2_im, on=['StudentID', 'endTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate ratio per window\n",
    "merged_df_im['ratio_IM'] = merged_df_im['total_time_IM_time_window'] / merged_df_im['total_time_IM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['ratio_IM'] = merged_df_im['ratio_IM'] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ratio YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by ID, month, and time window\n",
    "grouped = data.groupby(['StudentID', pd.Grouper(key='startTime', freq='6H'), pd.Grouper(key='endTime', freq='M'), 'timeWindow'])\n",
    "\n",
    "# Calculate the total time spent on gaming per ID, month, and time window\n",
    "result = grouped.apply(lambda x: x.loc[x['better_category_hybrid'] == 'YouTube', 'timeMinutes'].sum())\n",
    "\n",
    "result = result.reset_index(name='total_time_YT')\n",
    "\n",
    "# Rename the columns to match the desired output\n",
    "result.columns = ['StudentID', 'startTime', 'endTime', 'timeWindow', 'total_time_YT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['endTime'] = pd.to_datetime(result['endTime'])\n",
    "\n",
    "#group by student id and aggregate time monthly and aggregate a list with total minutes on media per time window\n",
    "group_yt = result.groupby(['StudentID', pd.Grouper(key='endTime', freq='M'), 'timeWindow'])['total_time_YT'].agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum the total minutes on  media for the whole month\n",
    "group2_yt = result.groupby(['StudentID', 'endTime'])['total_time_YT'].agg(sum)\n",
    "\n",
    "#merge the time windows with the total time on media\n",
    "merged_df_yt = pd.merge(group_yt, group2_yt, on=['StudentID', 'endTime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate youtube ratio per daily window \n",
    "merged_df_yt['ratio_YT'] = merged_df_yt['total_time_YT_x'] / merged_df_yt['total_time_YT_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['ratio_YT'] = merged_df_yt['ratio_YT'] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ratio Streaming Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by ID, month, and time window\n",
    "grouped = data.groupby(['StudentID', pd.Grouper(key='startTime', freq='6H'), pd.Grouper(key='endTime', freq='M'), 'timeWindow'])\n",
    "\n",
    "# Calculate the total time spent on gaming per ID, month, and time window\n",
    "result = grouped.apply(lambda x: x.loc[x['better_category'] == 'Streaming_Services', 'timeMinutes'].sum())\n",
    "\n",
    "result = result.reset_index(name='total_time_SS')\n",
    "\n",
    "# Rename the columns to match the desired output\n",
    "result.columns = ['StudentID', 'startTime', 'endTime', 'timeWindow', 'total_time_SS']\n",
    "\n",
    "result['endTime'] = pd.to_datetime(result['endTime'])\n",
    "\n",
    "##group by student id and aggregate time monthly and aggregate a list with total minutes on media per time window\n",
    "group_ss = result.groupby(['StudentID', pd.Grouper(key='endTime', freq='M'), 'timeWindow'])['total_time_SS'].agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum the total minutes on  media for the whole month\n",
    "group2_ss = result.groupby(['StudentID', 'endTime'])['total_time_SS'].agg(sum)\n",
    "\n",
    "#merge the time windows with the total time on media\n",
    "merged_df_ss = pd.merge(group_ss, group2_ss, on=['StudentID', 'endTime'])\n",
    "\n",
    "#calculate Ratio\n",
    "merged_df_ss['ratio_SS'] = merged_df_ss['total_time_SS_x'] / merged_df_ss['total_time_SS_y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['ratio_SS'] = merged_df_ss['ratio_SS'] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ratio Internet Browsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by ID, month, and time window\n",
    "grouped = data.groupby(['StudentID', pd.Grouper(key='startTime', freq='6H'), pd.Grouper(key='endTime', freq='M'), 'timeWindow'])\n",
    "\n",
    "# Calculate the total time spent on gaming per ID, month, and time window\n",
    "result = grouped.apply(lambda x: x.loc[x['better_category'] == 'Internet Browsing', 'timeMinutes'].sum())\n",
    "\n",
    "result = result.reset_index(name='total_time_BR')\n",
    "\n",
    "# Rename the columns to match the desired output\n",
    "result.columns = ['StudentID', 'startTime', 'endTime', 'timeWindow', 'total_time_BR']\n",
    "\n",
    "result['endTime'] = pd.to_datetime(result['endTime'])\n",
    "\n",
    "##group by student id and aggregate time monthly and aggregate a list with total minutes on media per time window\n",
    "group_br = result.groupby(['StudentID', pd.Grouper(key='endTime', freq='M'), 'timeWindow'])['total_time_BR'].agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum the total minutes on  media for the whole month\n",
    "group2_br = result.groupby(['StudentID', 'endTime'])['total_time_BR'].agg(sum)\n",
    "\n",
    "#merge the time windows with the total time on media\n",
    "merged_df_br = pd.merge(group_br, group2_br, on=['StudentID', 'endTime'])\n",
    "\n",
    "#calculate Ratio\n",
    "merged_df_br['ratio_BR'] = merged_df_br['total_time_BR_x'] / merged_df_br['total_time_BR_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['ratio_BR'] = merged_df_br['ratio_BR'] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ratio Dialer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by ID, month, and time window\n",
    "grouped = data.groupby(['StudentID', pd.Grouper(key='startTime', freq='6H'), pd.Grouper(key='endTime', freq='M'), 'timeWindow'])\n",
    "\n",
    "# Calculate the total time spent on gaming per ID, month, and time window\n",
    "result = grouped.apply(lambda x: x.loc[x['better_category'] == 'Dialer', 'timeMinutes'].sum())\n",
    "\n",
    "result = result.reset_index(name='total_time_dlr')\n",
    "\n",
    "# Rename the columns to match the desired output\n",
    "result.columns = ['StudentID', 'startTime', 'endTime', 'timeWindow', 'total_time_dlr']\n",
    "\n",
    "result['endTime'] = pd.to_datetime(result['endTime'])\n",
    "\n",
    "##group by student id and aggregate time monthly and aggregate a list with total minutes on media per time window\n",
    "group_dlr = result.groupby(['StudentID', pd.Grouper(key='endTime', freq='M'), 'timeWindow'])['total_time_dlr'].agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum the total minutes on  media for the whole month\n",
    "group2_dlr = result.groupby(['StudentID', 'endTime'])['total_time_dlr'].agg(sum)\n",
    "\n",
    "#merge the time windows with the total time on media\n",
    "merged_df_dlr = pd.merge(group_dlr, group2_dlr, on=['StudentID', 'endTime'])\n",
    "\n",
    "#calculate Ratio\n",
    "merged_df_dlr['ratio_dlr'] = merged_df_dlr['total_time_dlr_x'] / merged_df_dlr['total_time_dlr_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['ratio_dlr'] = merged_df_dlr['ratio_dlr']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ratio Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by ID, month, and time window\n",
    "grouped = data.groupby(['StudentID', pd.Grouper(key='startTime', freq='6H'), pd.Grouper(key='endTime', freq='M'), 'timeWindow'])\n",
    "\n",
    "# Calculate the total time spent on gaming per ID, month, and time window\n",
    "result = grouped.apply(lambda x: x.loc[x['better_category'] == 'Email', 'timeMinutes'].sum())\n",
    "\n",
    "result = result.reset_index(name='total_time_eml')\n",
    "\n",
    "# Rename the columns to match the desired output\n",
    "result.columns = ['StudentID', 'startTime', 'endTime', 'timeWindow', 'total_time_eml']\n",
    "\n",
    "result['endTime'] = pd.to_datetime(result['endTime'])\n",
    "\n",
    "##group by student id and aggregate time monthly and aggregate a list with total minutes on media per time window\n",
    "group_eml = result.groupby(['StudentID', pd.Grouper(key='endTime', freq='M'), 'timeWindow'])['total_time_eml'].agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum the total minutes on  media for the whole month\n",
    "group2_eml = result.groupby(['StudentID', 'endTime'])['total_time_eml'].agg(sum)\n",
    "\n",
    "#merge the time windows with the total time on media\n",
    "merged_df_eml = pd.merge(group_eml, group2_eml, on=['StudentID', 'endTime'])\n",
    "\n",
    "#calculate Ratio\n",
    "merged_df_eml['ratio_eml'] = merged_df_eml['total_time_eml_x'] / merged_df_eml['total_time_eml_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['ratio_eml'] = merged_df_eml['ratio_eml']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot table\n",
    "m_w_order = ['January_24-6', 'January_6-12', 'January_12-18', 'January_18-24', 'Fabruary_24-6', 'February_6-12', 'February_12-18', 'Fabruary_18-24', 'March_24-6', 'March_6-12', 'March_12-18', 'March_18-24', 'April_24-6', 'April_6-12', 'April_12-18', 'April_18-24', 'May_24-6', 'May_6-12', 'May_12-18', 'May_18-24', 'June_24-6', 'June_6-12', 'June_12-18', 'June_18-24', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "windows_new = pd.pivot_table(final, values=final.columns, index=final['StudentID'], columns=['month_window'])\n",
    "\n",
    "windows_new = windows_new.reindex(m_w_order, axis=1, level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten\n",
    "new_columns = [f\"{top_col}_{sub_col}\" for top_col, sub_col in windows_new.columns]\n",
    "\n",
    "windows_new.columns = new_columns\n",
    "windows_new.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "windows_new.to_csv(r'new_removed_tables\\ratio_daily_window_apps', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trend Slopes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Trend slopes of phone usage for all of the months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group the data\n",
    "gr_slope = new_data.groupby(['StudentID', 'month', 'day'])['minute'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "gr_slope['minute'] = pd.to_numeric(gr_slope['minute'])\n",
    "\n",
    "\n",
    "#group the data by 'UserID' in each sample\n",
    "grouped_data = gr_slope.groupby('StudentID')\n",
    "\n",
    "\n",
    "#create empty dataframes to store the results for each sample\n",
    "result_df = pd.DataFrame(columns=['StudentID', 'time_slope_on_phone'])\n",
    "\n",
    "\n",
    "#iterate over each group in sample 1\n",
    "for student_id, group in grouped_data:\n",
    "    # Extract the x values for linear regression\n",
    "    x = np.arange(len(group))  # Assuming time is represented by the index of the dataframe\n",
    "    \n",
    "    #perform linear regression for each variable and calculate the trend slope\n",
    "    s1 = linregress(x, group['minute']).slope\n",
    "\n",
    "    \n",
    "    # append the result to the result dataframe for sample 1\n",
    "    result_df = result_df.append({'StudentID': student_id,'time_slope_on_phone': s1}, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Trens slopes of phone usage for months: January-March and April-June"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the first sample from the beginning month to the end of the third month\n",
    "sample1 = gr_slope[gr_slope['month'].isin([1, 2, 3])]\n",
    "\n",
    "#create the second sample from the beginning of the fourth month to the end of the sixth month\n",
    "sample2 = gr_slope[gr_slope['month'].isin([4, 5, 6])]\n",
    "\n",
    "#group the data by 'UserID' in each sample\n",
    "grouped_data1 = sample1.groupby('StudentID')\n",
    "grouped_data2 = sample2.groupby('StudentID')\n",
    "\n",
    "#create empty dataframes to store the results for each sample\n",
    "result_df1 = pd.DataFrame(columns=['StudentID', 'time_slope_march'])\n",
    "result_df2 = pd.DataFrame(columns=['StudentID', 'time_slope_june'])\n",
    "\n",
    "#iterate over each group in sample 1\n",
    "for student_id, group in grouped_data1:\n",
    "    #extract the x values for linear regression\n",
    "    x = np.arange(len(group))  # Assuming time is represented by the index of the dataframe\n",
    "    \n",
    "    #perform linear regression for each variable and calculate the trend slope\n",
    "    s1 = linregress(x, group['minute']).slope\n",
    "\n",
    "    \n",
    "    # append the result to the result dataframe for sample 1\n",
    "    result_df1 = result_df1.append({'StudentID': student_id,'time_slope_march': s1}, ignore_index=True)\n",
    "\n",
    "#iterate over each group in sample 2\n",
    "for student_id, group in grouped_data2:\n",
    "    #extract the x values for linear regression\n",
    "    x = np.arange(len(group))  # Assuming time is represented by the index of the dataframe\n",
    "    \n",
    "    #perform linear regression for each variable and calculate the trend slope\n",
    "    s2 = linregress(x, group['minute']).slope\n",
    "\n",
    "\n",
    "    result_df2 = result_df2.append({'StudentID': student_id,\n",
    "                                    'time_slope_june': s2}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results\n",
    "\n",
    "result_df1.to_csv(r'new_removed_tables\\phone_usage_trend_slope_march.csv', index=False)\n",
    "result_df2.to_csv(r'new_removed_tables\\phone_usage_trend_slope_june.csv', index=False)\n",
    "result_df = pd.read_csv(r'new_removed_tables\\phone_usage_trend_slope_all_months.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Trend slopes of app usage for all of the months\n",
    "- app categories: 'Instant_Messaging', 'Social_Networking', 'Streaming_Services', 'Email', 'Dialer', 'Internet_Browser'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of the values\n",
    "\n",
    "trend_columns = ['Instant_Messaging', 'Social_Networking', 'Streaming_Services', 'Email', 'Dialer', 'Internet_Browser']\n",
    "\n",
    "\n",
    "\n",
    "#group the data by 'StudentID' in each sample\n",
    "grouped_data = new_data.groupby('StudentID')\n",
    "\n",
    "\n",
    "# create empty dataframes to store the results for each sample\n",
    "result_df = pd.DataFrame(columns=['StudentID'] + trend_columns)\n",
    "\n",
    "\n",
    "# calculate trend slopes for sample 1\n",
    "for student_id, group in grouped_data:\n",
    "    trends1 = {'StudentID': student_id}\n",
    "    for category in trend_columns:\n",
    "        category_data = group[group['better_category'] == category]\n",
    "        if len(category_data) > 1:\n",
    "            x = np.arange(len(category_data))\n",
    "            y = category_data['minute']\n",
    "            slope = linregress(x, y).slope\n",
    "        else:\n",
    "            slope = np.nan\n",
    "        trends1[category] = slope\n",
    "    result_df = result_df.append(trends1, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results\n",
    "result_df.to_csv(r'new_removed_tables\\app_usage_all_months.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Trend slopes of app usage for months: January-March and April-June"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "#create list of the values\n",
    "trend_columns = ['Instant_Messaging', 'Social_Networking', 'Streaming_Services', 'Email', 'Dialer', 'Internet_Browser']\n",
    "\n",
    "# Group the data by 'StudentID' in each sample\n",
    "grouped_data = new_data.groupby('StudentID')\n",
    "\n",
    "# Create empty dataframes to store the results for each sample\n",
    "result_df_march = pd.DataFrame(columns=['StudentID'] + [col + '_march' for col in trend_columns])\n",
    "result_df_june = pd.DataFrame(columns=['StudentID'] + [col + '_june' for col in trend_columns])\n",
    "\n",
    "# Calculate trend slopes for sample 1 (March)\n",
    "for student_id, group in grouped_data:\n",
    "    trends_march = {'StudentID': student_id}\n",
    "    march_data = group[group['month'].between(1, 3)]\n",
    "    for category in trend_columns:\n",
    "        category_data = march_data[march_data['better_category'] == category]\n",
    "        if len(category_data) > 1:\n",
    "            x = np.arange(len(category_data))\n",
    "            y = category_data['minute']\n",
    "            slope = linregress(x, y).slope\n",
    "        else:\n",
    "            slope = np.nan\n",
    "        trends_march[category + '_march'] = slope\n",
    "    result_df_march = result_df_march.append(trends_march, ignore_index=True)\n",
    "\n",
    "# Calculate trend slopes for sample 2 (June)\n",
    "for student_id, group in grouped_data:\n",
    "    trends_june = {'StudentID': student_id}\n",
    "    june_data = group[group['month'].between(4, 6)]\n",
    "    for category in trend_columns:\n",
    "        category_data = june_data[june_data['better_category'] == category]\n",
    "        if len(category_data) > 1:\n",
    "            x = np.arange(len(category_data))\n",
    "            y = category_data['minute']\n",
    "            slope = linregress(x, y).slope\n",
    "        else:\n",
    "            slope = np.nan\n",
    "        trends_june[category + '_june'] = slope\n",
    "    result_df_june = result_df_june.append(trends_june, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results\n",
    "result_df_march.to_csv(r'new_removed_tables\\app_usage_march.csv')\n",
    "result_df_june.to_csv(r'new_removed_tables\\app_usage_june.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat the slopes tables\n",
    "\n",
    "result_df.set_index('StudentID', inplace=True)\n",
    "result_df_march.set_index('StudentID', inplace=True)\n",
    "result_df_june.set_index('StudentID', inplace=True)\n",
    "\n",
    "merged_tables3 = result_df.merge(result_df_march, on='StudentID', how='left')\n",
    "merged_tables4 =  merged_tables3.merge(result_df_june, on='StudentID', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save concatenated columns\n",
    "merged_tables4.to_csv(r'new_removed_tables\\app_usage_slopes_all_march_june_ANALYSIS.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
