{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import os\n",
    "from sklearn.impute import KNNImputer\n",
    "from shapely.geometry import Point, Polygon\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "data = pd.read_csv(r'Thesis data\\combined.csv', dtype='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecessary columns\n",
    "data.drop(['notification', 'notificationId', 'application', 'battery', 'surveyId', 'startTime', 'endTime',\n",
    " 'startTimeMillis', 'endTimeMillis', 'session', 'id', 'model', 'studyKey', 'data_version'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for missings\n",
    "data[['longitude', 'latitude']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get description of the data\n",
    "data[['longitude', 'latitude']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the invalid values\n",
    "import re\n",
    "def clean_coordinates(value):\n",
    "    #remove non-numeric characters\n",
    "    cleaned_value = re.sub('[^0-9.-]', '', value)\n",
    "\n",
    "    # Retain only the first dot\n",
    "    dot_index = cleaned_value.find('.')\n",
    "    cleaned_value = cleaned_value[:dot_index + 1] + cleaned_value[dot_index + 1:].replace('.', '')\n",
    "\n",
    "    return cleaned_value\n",
    "\n",
    "\n",
    "#assuming you have a DataFrame named 'data' with 'latitude' and 'longitude' columns\n",
    "data['latitude'] = data['latitude'].apply(clean_coordinates)\n",
    "data['longitude'] = data['longitude'].apply(clean_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the values to float\n",
    "data['latitude'] = data['latitude'].astype(float)\n",
    "data['longitude'] = data['longitude'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the data points\n",
    "\n",
    "#plotting the GPS data points\n",
    "plt.figure(figsize=(10, 6))  # Set the figure size as desired\n",
    "\n",
    "#scatter plot of lon/lat data points\n",
    "plt.scatter(data1['longitude'], data1['latitude'], s=10) \n",
    "plt.xlim(data['longitude'].min() - 0.1, data['longitude'].max() + 0.1)\n",
    "plt.ylim(data['latitude'].min() - 0.1, data['latitude'].max() + 0.1)\n",
    "# Set plot title and axis labels\n",
    "plt.title('GPS Data Points')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "\n",
    "plt.show()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove outliers \n",
    "\n",
    "\n",
    "lat_range = (-90, 90)\n",
    "lon_range = (-180, 180)\n",
    "\n",
    "#filter and replace out-of-range values with NaN\n",
    "data.loc[data['latitude'].between(*lat_range), 'latitude'] = np.nan\n",
    "data.loc[data['longitude'].between(*lon_range), 'longitude'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cgeck for missings after the cleaning\n",
    "\n",
    "data[['longitude', 'latitude']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize after the cleaning\n",
    "\n",
    "\n",
    "#plotting the GPS data points\n",
    "plt.figure(figsize=(10, 6))  # Set the figure size as desired\n",
    "\n",
    "#scatter plot of lon/lat data points\n",
    "plt.scatter(data1['longitude'], data1['latitude'], s=10)  \n",
    "plt.xlim(data['longitude'].min() - 0.1, data['longitude'].max() + 0.1)\n",
    "plt.ylim(data['latitude'].min() - 0.1, data['latitude'].max() + 0.1)\n",
    "#set plot title and axis labels\n",
    "plt.title('GPS Data Points')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the locations on the map\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "#create a new figure\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "#crreate a Basemap object\n",
    "m = Basemap(projection='mill', llcrnrlat=-90, urcrnrlat=90, llcrnrlon=-180, urcrnrlon=180, resolution='c')\n",
    "\n",
    "#draw coastlines, countries, and states\n",
    "m.drawcoastlines()\n",
    "m.drawcountries()\n",
    "m.drawstates()\n",
    "\n",
    "# plot latitude and longitude data\n",
    "lon = data['longitude']\n",
    "lat = data['latitude']\n",
    "x, y = m(lon, lat)\n",
    "m.scatter(x, y, marker='o', color='red', zorder=10, s=1)\n",
    "\n",
    "# addd a title\n",
    "plt.title('Latitude and Longitude Data')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN missing data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate the lon/lat columns\n",
    "lon_lat_data = data[['longitude', 'latitude']]\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "imputed_data = pd.DataFrame(imputer.fit_transform(lon_lat_data), columns=['longitude', 'latitude'])\n",
    "\n",
    "#update the original DataFrame with the imputed values\n",
    "data['longitude'] = imputed_data['longitude']\n",
    "data['latitude'] = imputed_data['latitude']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create polygons for extracting campus location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop longitude and latitude duplicates\n",
    "#copy on a new dataset\n",
    "\n",
    "data1 = data.drop_duplicates(['longitude', 'latitude'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of tuples with the geographic points\n",
    "campus_polygon = [(5.0427518, 51.5662584), (5.0409279, 51.562777), (5.0391469, 51.561203), (5.045198, 51.5599623), (5.0455842, 51.5619633), (5.0567637, 51.5612163), (5.0569139, 51.5624035), (5.0509272, 51.5628971), (5.0455628, 51.5631639), (5.046228, 51.5656582), (5.0428695, 51.5660852)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create polygon\n",
    "polygon = Polygon(campus_polygon)\n",
    "\n",
    "\n",
    "# Add a new column to store the point-in-polygon status\n",
    "data_1['is_inside'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create boolean column indentifying wether location celongs to campus or not\n",
    "\n",
    "for index, row in data_1.iterrows():\n",
    "    point = Point(row['longitude'], row['latitude'])\n",
    "    is_inside = point.within(polygon)\n",
    "    data_1.at[index, 'is_inside'] = is_inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how many locations are 'on campus'\n",
    "print(data_1['is_inside'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter only on campus\n",
    "#filter only the true values\n",
    "data_true = data_1[data_1['is_inside']== True]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add 'on campus' column on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create boolean on the whole dataset\n",
    "\n",
    "data['on_campus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#point that fall into the region on the polygon; whole dataset\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    point = Point(row['longitude'], row['latitude'])\n",
    "    is_inside = point.within(polygon)\n",
    "    data.at[index, 'on_campus'] = is_inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the value counts\n",
    "print(data['on_campus'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "data.to_csv(r'C:\\Users\\maria\\Desktop\\Final data\\location features\\on_campus_data.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add 'on campus' column to the app event dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_events = pd.read_csv(r'Thesis data\\combined.csv', dtype='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set index to both of the datasets\n",
    "app_events.set_index('StudentID', inplace=True)\n",
    "data.set_index('StudentID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the two datasets\n",
    "locations = pd.concat([app_events, data], axis=1 )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert time to datetime\n",
    "locations['startTime'] = pd.to_datetime(locations['startTime'])\n",
    "locations['endTime'] = pd.to_datetime(locations['endTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create month name column\n",
    "\n",
    "locations['month_name'] = pd.to_datetime(locations['startTime']).dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create date column\n",
    "\n",
    "locations['date'] = locations['startTime'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#month column\n",
    "\n",
    "locations['month'] = (locations['endTime']).dt.strftime('%Y-%m')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Time spent on campus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = locations.groupby(['StudentID', 'month', 'date'])\n",
    "\n",
    "def calculate_total_time_on_campus(group):\n",
    "    on_campus_rows = group.loc[group['on_campus']]\n",
    "    if len(on_campus_rows) > 0:\n",
    "        total_time = (on_campus_rows['endTime'].iloc[-1] - on_campus_rows['startTime'].iloc[0]).total_seconds() / 60\n",
    "    else:\n",
    "        total_time = 0\n",
    "    return total_time\n",
    "\n",
    "result = grouped.apply(calculate_total_time_on_campus).reset_index(name='total_time_on_campus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe with time on campus\n",
    "time_campus = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total time in minutes spent on campus every month\n",
    "sum_time_campus = time_campus.groupby(['StudentID', 'month'])['total_time_on_campus'].sum().reset_index(name= 'time_on_campus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save total time on campus\n",
    "sum_time_campus.to_csv(r'C:\\Users\\maria\\Desktop\\Final data\\new_datasets\\university_time.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Number of unibersity visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'StudentID', 'month', and 'date'\n",
    "grouped = locations.groupby(['StudentID', 'month', 'date'])\n",
    "\n",
    "# Calculate the number of unique days the campus was visited per month for each student\n",
    "result = grouped['on_campus'].any().groupby(['StudentID', 'month']).sum().reset_index(name='days_visited_on_campus')\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the months with most visits\n",
    "sns.barplot(result, x='month', y='days_visited_on_campus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Group the data by month and calculate the total number of visits\n",
    "monthly_visits = result.groupby('month')['days_visited_on_campus'].sum()\n",
    "\n",
    "# Sort the months based on the total number of visits in descending order\n",
    "sorted_months = monthly_visits.sort_values(ascending=False)\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "sorted_months.plot(kind='bar', color='blue')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Visits')\n",
    "plt.title('Number of Visits per Month')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save uni visits\n",
    "result.to_csv(r'new_datasets\\university_visits.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
